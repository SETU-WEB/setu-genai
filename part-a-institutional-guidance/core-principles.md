---
description: >-
  Reliability, Honesty, Respect, and Accountability — the EU Living Guidelines
  framework
---

# Core Principles

> **Page description:** _Reliability, Honesty, Respect, and Accountability — the EU Living Guidelines framework_

## Core Principles

The use of GenAI in research must be underpinned by the notion of **human agency and human oversight**. Researchers remain ultimately responsible for all aspects of their scientific outputs, including accountability for the integrity, accuracy, validity, and originality of all content in their research outputs.

These principles are framed around the [EU Living Guidelines on the Responsible Use of Generative AI in Research](https://research-and-innovation.ec.europa.eu/):

### Reliability

Ensuring the quality of research, reflected in the design, methodology, analysis and use of resources. This includes **verifying and reproducing** information produced by AI for research, and being aware of possible equality and non-discrimination issues in relation to bias and inaccuracies.

### Honesty

Developing, carrying out, reviewing, reporting and communicating on research **transparently, fairly, thoroughly and impartially**. This principle includes disclosing that generative AI has been used, what tools have been used, how they have been used and for what purposes.

### Respect

For colleagues, research participants, research subjects, society, and the environment. Responsible use of generative AI should consider the **limitations of the technology, its environmental impact** and its societal effects (bias, diversity, non-discrimination, fairness and prevention of harm).

### Accountability

For the research from idea to publication, for its management and organisation, for training, supervision and mentoring, and for its wider societal impacts. **Researchers remain ultimately responsible** for all aspects of their scientific outputs, including the integrity, accuracy, validity, and originality of all content.

### Applying Principles Across AI Usage Levels

These principles have different implications depending on the level of AI involvement in a task. See The Five-Level Framework for how these principles apply at each level of AI usage.

| Principle      | Low AI Use (L1–2)            | Moderate AI Use (L3)                      | High AI Use (L4–5)                              |
| -------------- | ---------------------------- | ----------------------------------------- | ----------------------------------------------- |
| Reliability    | Standard verification        | Additional verification of AI suggestions | Rigorous independent validation required        |
| Honesty        | Acknowledge any use          | Document AI's role in shaping outputs     | Full disclosure of AI contribution              |
| Respect        | Standard ethics              | Consider AI limitations in outputs        | Scrutinise for bias amplification               |
| Accountability | Researcher fully accountable | Researcher accountable for AI-shaped work | Researcher accountable for AI-generated content |
